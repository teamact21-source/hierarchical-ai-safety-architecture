# Hierarchical AI Safety Architecture

This repository contains a research paper proposing a hierarchical AI safety model in which a human-like Primary AI (PA) is supervised by a strictly superior Supervisory AI (SA).

The architecture preserves expressiveness and creativity for users while ensuring robust safety through asymmetric capability dominance.

## Contents
- `paper.md` — Full research paper  
- `figures/architecture.svg` — System diagram  

## Paper
The full paper is available here:  
 [paper.md](paper.md)

## Summary
Conventional rule-based guardrails fail due to combinatorial explosion and adversarial prompting.  
This architecture replaces surface-level filters with **structural dominance**, enabling an expressive user-facing model that remains safe under oversight by a superior system.

## License
No license has been selected yet.
